{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error as RMSE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "**Overall Goals**\n",
    "\n",
    "The Goal of this project is 2 fold.  The first is to perform import, and analysis, and predictions of the BBC News dataset using Non-Negative Matrix Factorization.  There will be testing with various sizes of training data and various levels of reduction as well as 3 or 4 different algorithims to perform predictions. \n",
    "\n",
    "As I have never done text analasys before I used [https://towardsdatascience.com/using\\-nmf\\-to\\-classify\\-companies\\-a77e176f276f](https://towardsdatascience.com/using-nmf-to-classify-companies-a77e176f276f)  as a guide on how to do this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:medium'>**Import and EDA**</span>\n",
    "\n",
    "I am analyzing BBC news articles with the goal of being able to categorize the news articles.  I start by importing the data and factorizing the data.  I split the data using TF\\-IDF which uses the count of words penalized by how often the word happens in different documents.  It returns values for each word between 0 and 1 with 0 being not present.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ArticleId                                               Text  Category\n",
      "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
      "1        154  german business confidence slides german busin...  business\n",
      "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
      "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
      "4        917  enron bosses in $168m payout eighteen former e...  business\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/isaac1987a/Week-4/main/BBC/Data/BBC_News_Train.csv?token=GHSAT0AAAAAACEVGSIJOLNMPFLVDU6S4NPCZFMJTXA\")\n",
    "print(data.head())\n",
    "vectorizer = TfidfVectorizer(input='content', encoding='utf-8', \n",
    "                             decode_error='strict', strip_accents='unicode', \n",
    "                             lowercase=True, preprocessor=None, tokenizer=None, \n",
    "                             analyzer='word', max_df=1.0, min_df=1, max_features=None, \n",
    "                             sublinear_tf=True, ngram_range=(1,2))\n",
    "#Combine Data into category matricies\n",
    "data = data.drop(columns = ['ArticleId'])\n",
    "\n",
    "#Vectorize Results\n",
    "text_matrix = vectorizer.fit_transform(data.Text)\n",
    "#Sparse Matrix of results\n",
    "#print(text_matrix)\n",
    "#Get Word List\n",
    "word_list = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           00  00 and  00 for  00 mark  00 per       000  000 12  000 130  \\\n",
      "business  0.0     0.0     0.0      0.0     0.0  0.000000     0.0      0.0   \n",
      "business  0.0     0.0     0.0      0.0     0.0  0.000000     0.0      0.0   \n",
      "business  0.0     0.0     0.0      0.0     0.0  0.014521     0.0      0.0   \n",
      "tech      0.0     0.0     0.0      0.0     0.0  0.013526     0.0      0.0   \n",
      "business  0.0     0.0     0.0      0.0     0.0  0.000000     0.0      0.0   \n",
      "\n",
      "          000 133  000 267  ...  zurich according  zurich and  \\\n",
      "business      0.0      0.0  ...               0.0         0.0   \n",
      "business      0.0      0.0  ...               0.0         0.0   \n",
      "business      0.0      0.0  ...               0.0         0.0   \n",
      "tech          0.0      0.0  ...               0.0         0.0   \n",
      "business      0.0      0.0  ...               0.0         0.0   \n",
      "\n",
      "          zurich premiership  zutons  zutons at  zvonareva  zvonareva has  \\\n",
      "business                 0.0     0.0        0.0        0.0            0.0   \n",
      "business                 0.0     0.0        0.0        0.0            0.0   \n",
      "business                 0.0     0.0        0.0        0.0            0.0   \n",
      "tech                     0.0     0.0        0.0        0.0            0.0   \n",
      "business                 0.0     0.0        0.0        0.0            0.0   \n",
      "\n",
      "          zvonareva russia  zvonareva struggled  zvonareva while  \n",
      "business               0.0                  0.0              0.0  \n",
      "business               0.0                  0.0              0.0  \n",
      "business               0.0                  0.0              0.0  \n",
      "tech                   0.0                  0.0              0.0  \n",
      "business               0.0                  0.0              0.0  \n",
      "\n",
      "[5 rows x 268973 columns]\n",
      "(1490, 268973)\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to array\n",
    "text_array = text_matrix.toarray()\n",
    "\n",
    "# Create pandas dataframe with column names as word_list\n",
    "text_dataframe = pd.DataFrame(text_array, columns=word_list)\n",
    "text_dataframe.index = list(data.Category)\n",
    "# Print first few rows of resulting dataframe\n",
    "print(text_dataframe.head())\n",
    "print(text_dataframe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, I validated that all categories are fairly well balanced.  This ensures that I don't have to do any normalizing for unblalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#shows the data is balanced between categories\n",
    "def plot_balance(dat):\n",
    "    plot2 = plt.hist(dat.index)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Count of items in categories Categories')\n",
    "    plt.show()\n",
    "plot_balance(text_dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now selected the most common words for each category by adding the values of each column.  This turned into an unexpected result.  Common words have distinct categories of association, but the top 10 words are very commonly shared too.  I'm going to reload the dataset while excluding common English words.\n",
    "\n",
    "I have no idea where the 6th color is coming from.  I gave up looking.  If you figure it out, please drop me a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The plot the sum of each categories words.\n",
    "def graph_frame(text_dataframe):\n",
    "    grouped_frame = text_dataframe.groupby(level = 0).sum()\n",
    "\n",
    "    top_n = 10\n",
    "    colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    for i, category in enumerate(grouped_frame.index):\n",
    "        top_words = grouped_frame.loc[category].sort_values(ascending=False).iloc[:top_n]\n",
    "        ax.bar(top_words.index, top_words.values, color=colors[i], alpha=0.7, label=category)\n",
    "\n",
    "    ax.set_xlabel('Words')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'Top {top_n} Words by Category')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "graph_frame(text_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing the data, there are few words and they have lots of overlap between categories.  I researched and found that TfidfVectorizer has the option to remove words.  I used the built in list of common words from the English language.  This seems to have resolved the overlap and now I have each category with distinct most common words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"https://gist.githubusercontent.com/deekayen/4148741/raw/98d35708fa344717d8eee15d11987de6c8e26d7d/1-1000.txt\", header = None)[0:100]\n",
    "vectorizer = TfidfVectorizer(input='content', encoding='utf-8', \n",
    "                             decode_error='strict', strip_accents='unicode', \n",
    "                             lowercase=True, preprocessor=None, tokenizer=None, \n",
    "                             analyzer='word', max_df=1.0, min_df=1, max_features=None, \n",
    "                             sublinear_tf=True, ngram_range=(1,2), stop_words = stopwords.T.values.tolist()[0])\n",
    "#Vectorize Results\n",
    "text_matrix = vectorizer.fit_transform(data.Text)\n",
    "#Sparse Matrix of results\n",
    "#print(text_matrix)\n",
    "#Get Word List\n",
    "word_list = vectorizer.get_feature_names_out()\n",
    "# Convert sparse matrix to array\n",
    "text_array = text_matrix.toarray()\n",
    "\n",
    "# Create pandas dataframe with column names as word_list\n",
    "text_dataframe = pd.DataFrame(text_array, columns=word_list)\n",
    "text_dataframe.index = list(data.Category)\n",
    "# Print first few rows of resulting dataframe\n",
    "#print(text_dataframe.head())\n",
    "#print(text_dataframe.shape)\n",
    "graph_frame(text_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I considered cleaning up this more to get more pure data, however I decided that it would be more intresting to leave the data with some ambiguities in words to see what would happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will use Non\\-Negative Matrix Factorization to reduce the size of the data set.  I will begin with a 90/10 train test split and move down to 50/50 20/80 and 10/90 to compare.  I will also see if I can find a most efficient C value for shrinking the dataset.   These initial steps are all being set up as funcitons so I can automate and make pretty graphs later on. \n",
    "\n",
    "To start with, I will split my data into train and test sets.  I split the data 90/10 and verified that the categories are similar in size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Function to split the data and drop a chart to verify that the \n",
    "def split_data(df, percent):\n",
    "    train_data, test_data = train_test_split(df, train_size=percent/100, random_state=42)    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = split_data(text_dataframe, 90)\n",
    "plot_balance(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the datasets are similar in size preventing the need for normalizaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using T-SNE, the data is clearly categorized even when dimmension reduced to 2 factors.  There are some outliers, but it is pretty good.  The number of outliers may restrict me from usng a nearest neighbor model on the transformed data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "graph_vals = tsne.fit_transform(text_dataframe)\n",
    "print(graph_vals.shape)\n",
    "plot3 = sns.scatterplot(x = graph_vals[:,0], y = graph_vals[:,1], hue = text_dataframe.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Transformation**\n",
    "I started with a C of 50 for data transformation.  This is a very large value to start with, but I had to start somewhere.  A C of 50 doesn't work well and exceeds the 200 iteration threshold to properly calclate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Copied from https://towardsdatascience.com/using-nmf-to-classify-companies-a77e176f276f\n",
    "def create_model(train_data, c):\n",
    "    #print(train_data)\n",
    "    #train_data = csr_matrix(train_data)\n",
    "    model = NMF(n_components=c, init='random', random_state=0, solver = 'mu')\n",
    "    model = model.fit(train_data, c)\n",
    "    #H = model.components_\n",
    "    #err = model.reconstruction_err_\n",
    "    return (model)\n",
    "train_model = create_model(train_data, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#print(train_model.transform(train_data).shape)\n",
    "#print(train_model.transform(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Testing\n",
    "\n",
    "I want to compare models at this size so I will test a variety of modles to see which one does the best at 50 factors.  I plan to test K-Means, and Hierarchical clustering for unsupervised.  I wall aslo use Random Forrest, and KNN as a Supervised comparison.  I will be testing these all on 50, 40, 30, 20, 15, 10, 5, 3, and 2 factors.  The train/test splits will be 90/10, 50/50, 20,80, and 10,90.  This will generate a great many confusion matricies and take a long time to calculate all of this.  I will embed static images for you to not have to run everyting over a few hours.\n",
    "\n",
    "**K-Means**\n",
    "\n",
    "K-Means was used with Train N /5 clusters.  The multiplicative solver was used to speed up solve time.  After clusers were built, each cluster was assigned a category based on the most common category for each.  The test set was predicted and the categories were tested on the training categories.\n",
    "\n",
    "**Heirarcheral Agglomerative Clustering**\n",
    "\n",
    "Heirarcheral Agglomerative Clustering is a unsupervised teqnique that is common for text analasys.  This uses a bottom up teqnique to combine points until a prediciton tree is built.  Agglomerative clustering is designed to cluser data and does not have the ability to predict new points.  Theirfore I will be only calculating the success of clustering the training set and evaluating which points do not match the larger group.  I will be using the N/5 clusters.\n",
    "\n",
    "**Random Forrest**\n",
    "\n",
    "Random forrest is a similar teqnique to Heirarcheral Agglomerative Clustering,  however random forrest works from the top down to the leaves splitting on categories.  I will use random forrest with the min split being 5 points and 100 random trees.\n",
    "\n",
    "**K-Nearest Neighbor**\n",
    "\n",
    "KNN is a classification algorithim that uses the nearest neighbors to classify points.  This teqnique is part of how Agglomerative Clustering chooses it's cluster points, however KNN chooses the category based on the nearest neighbors while Agglomerative Clustering uses this to determine clusters as a unsupervised teqnique.  I will be using 1, 3, and 5, endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_Means_Build_and_Test(train_W, test_W, train_data, test_data):\n",
    "    n_clusters = int(train_W.shape[0]/10)\n",
    "    model = KMeans(n_clusters=n_clusters, max_iter=300, n_init = 'auto')\n",
    "    fitted_data = model.fit(scale(train_W))\n",
    "    \n",
    "    #use train data labels with W to label each cluster\n",
    "    train_predict = model.predict(scale(train_W))\n",
    "    train_predict = pd.DataFrame(zip(train_data.index, train_predict), columns = ['label', 'group'])\n",
    "    #print(train_predict_labels.groupby(['group', 'label']).size())\n",
    "    val = train_predict.groupby(['group', 'label']).size().to_frame()\n",
    "    train_predict = val.loc[val.groupby(\"group\")[0].idxmax()][0]\n",
    "    #print(train_predict)\n",
    "    train_predict_labels = pd.DataFrame(list(train_predict.index), columns = ['group', 'label'])\n",
    "    #print(train_predict_labels)\n",
    "    \n",
    "    #Use transformed test data to predict \n",
    "    test_predict = model.predict(scale(test_W))\n",
    "    test_predict_labels = pd.DataFrame(zip(test_data.index, test_predict), columns = ['actual', 'group'])\n",
    "    \n",
    "    #Validate predictions on test lables\n",
    "    test_predict_labels['label'] = None\n",
    "    test_predict_labels = test_predict_labels.merge(train_predict_labels, on = 'group', how = 'left')\n",
    "    test_predict_labels = test_predict_labels.drop(['group', 'label_x'], axis = 1)\n",
    "    test_predict_labels = test_predict_labels.rename({'actual' : 'actual', 'label_y': 'predict'}, axis = 1)\n",
    "    #print(test_W.shape)\n",
    "    #print(test_predict_labels)\n",
    "    \n",
    "    #return values for RMSE and F1    \n",
    "    return test_predict_labels\n",
    "    \n",
    "#model_build_and_test(W, train_data, test_data, 50)\n",
    "\n",
    "#df = K_Means_Build_and_Test(train_model.transform(train_data), train_model.transform(test_data), train_data, test_data)\n",
    "\n",
    "def heiracheral_clustering(train_W, train_data):\n",
    "    n_clusters = int(train_W.shape[0]/10)\n",
    "    model = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    fitted_data = model.fit_predict(scale(train_W))\n",
    "    #use train data labels with W to label each cluster\n",
    "\n",
    "    train_predict = pd.DataFrame(zip(train_data.index, fitted_data), columns = ['label', 'group'])\n",
    "    #print(train_predict.shape)\n",
    "    val = train_predict.groupby(['group', 'label']).size().to_frame()\n",
    "    train_predict = val.loc[val.groupby(\"group\")[0].idxmax()][0]\n",
    "    train_predict_labels = pd.DataFrame(list(train_predict.index), columns = ['group', 'label'])\n",
    "\n",
    "    #Use transformed test data to build test set \n",
    "    test_predict_labels = pd.DataFrame(zip(train_data.index, fitted_data), columns = ['actual', 'group'])\n",
    "    \n",
    "    #Validate predictions on test lables\n",
    "    test_predict_labels['label'] = None\n",
    "    test_predict_labels = test_predict_labels.merge(train_predict_labels, on = 'group', how = 'left')\n",
    "    test_predict_labels = test_predict_labels.drop(['group', 'label_x'], axis = 1)\n",
    "    test_predict_labels = test_predict_labels.rename({'actual' : 'actual', 'label_y': 'predict'}, axis = 1)\n",
    "    #print(test_predict_labels)\n",
    "    #Test for perfect predictions\n",
    "    #print(sum(test_predict_labels['actual'] == test_predict_labels['predict']))\n",
    "    return test_predict_labels\n",
    "    \n",
    "#Heiracheral_clustering(train_model.transform(train_data), train_data)\n",
    "\n",
    "def random_forrest(train_W, test_W, train_data, test_data):\n",
    "    #Generate Random Forrest and Fit Data\n",
    "    model  = RandomForestClassifier(n_estimators=100, criterion='gini', \n",
    "                                    max_depth=None, min_samples_split=5, \n",
    "                                    min_samples_leaf=3, min_weight_fraction_leaf=0.0, \n",
    "                                    max_features='sqrt', max_leaf_nodes=None, \n",
    "                                    min_impurity_decrease=0.0, bootstrap=True, \n",
    "                                    oob_score=False, n_jobs=None, random_state=None, \n",
    "                                    verbose=0, warm_start=False, class_weight=None, \n",
    "                                    ccp_alpha=0.0, max_samples=None)\n",
    "    \n",
    "    model.fit(scale(train_W), train_data.index)\n",
    "    #predict test set\n",
    "    test_predict = model.predict(scale(test_W))\n",
    "    test_predict_labels = pd.DataFrame(zip(test_data.index, test_predict), columns = ['actual', 'predict'])\n",
    "    #print(test_predict_labels)\n",
    "    #print(sum(test_predict_labels['actual'] == test_predict_labels['predict']))\n",
    "    return(test_predict_labels)\n",
    "\n",
    "#random_forrest(train_model.transform(train_data), train_model.transform(test_data), train_data, test_data)\n",
    "\n",
    "def nearest_neighbor(train_W, test_W, train_data, test_data, n_neighbors):\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights='uniform', \n",
    "                                 algorithm='auto', leaf_size=30, p=2, \n",
    "                                 metric='minkowski', metric_params=None, \n",
    "                                 n_jobs=None)\n",
    "    model.fit(scale(train_W), train_data.index)\n",
    "    test_predict = model.predict(scale(test_W))\n",
    "    test_predict_labels = pd.DataFrame(zip(test_data.index, test_predict), columns = ['actual', 'predict'])\n",
    "    #print(sum(test_predict_labels['actual'] == test_predict_labels['predict']))\n",
    "    #print(test_predict_labels)\n",
    "    return(test_predict_labels)\n",
    "df = nearest_neighbor(train_model.transform(train_data), train_model.transform(test_data), train_data, test_data, 1)  \n",
    "\n",
    "def make_metrics(df):\n",
    "    f1 = f1_score(df['actual'], df['predict'], average='macro')\n",
    "    f1 = \"F1 Score: \" + str(round(f1, 5))\n",
    "    precision = precision_score(df['actual'], df['predict'], average='macro')\n",
    "    precision = \"Precsion: \"+ str(round(precision, 5))\n",
    "    recall =  recall_score(df['actual'], df['predict'], average='macro')\n",
    "    recall = \"Recall: \"+ str(round(recall, 5))\n",
    "    return (f1, precision, recall)\n",
    "\n",
    "# Confusion Matrix From https://vitalflux.com/python-draw-confusion-matrix-matplotlib/#Confusion_Matrix_using_Matplotlib\n",
    "def make_confusion_matrix(df, title, axes, first_row = 0):\n",
    "    labels = np.array(['business', 'entertainment', 'politics', 'sports', 'tech'])\n",
    "    cm = confusion_matrix(df['actual'], df['predict'], labels = labels)\n",
    "    #print(cm)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = labels)\n",
    "    cm_display = cm_display.plot(ax=axes, xticks_rotation=30)\n",
    "    cm_display.ax_.set_title(title)\n",
    "    if first_row == 1:\n",
    "        cm_display.ax_.set_xlabel(\"\")\n",
    "        cm_display.ax_.set_ylabel(\"Actual\")\n",
    "    else: \n",
    "        cm_display.ax_.set_xlabel(\"\")\n",
    "        cm_display.ax_.set_ylabel(\"\")\n",
    "        cm_display.ax_.get_yaxis().set_visible(False)\n",
    "        \n",
    "    cm_display.im_.colorbar.remove()\n",
    "    cm_display.ax_.text(0.5, -0.3, \"\\n\".join(list(make_metrics(df))), transform=cm_display.ax_.transAxes,\n",
    "                                     horizontalalignment='center', verticalalignment='top')\n",
    "    return cm_display\n",
    "    \n",
    "    \n",
    "#make_confusion_matrix(df, \"Title\")\n",
    "\n",
    "#print(make_metrics(df))\n",
    "def make_metrics_clean(df):\n",
    "    f1 = f1_score(df['actual'], df['predict'], average='macro')\n",
    "    precision = precision_score(df['actual'], df['predict'], average='macro')\n",
    "    recall =  recall_score(df['actual'], df['predict'], average='macro')\n",
    "    return (f1, precision, recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Caution.  This takes a very long time to run.  Static Image Results Below.  Uncomment this block if you want any kind of Performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_build_and_test(train_data, test_data, C, data_split):\n",
    "    #C will be a list of C values to test\n",
    "    # Build W and test W\n",
    "    \n",
    "    this_c = C\n",
    "    train_model= create_model(train_data, this_c)\n",
    "    train_W = train_model.transform(train_data)\n",
    "    test_W = train_model.transform(test_data)\n",
    "    #K-Means\n",
    "    \n",
    "    KMC = K_Means_Build_and_Test(train_model.transform(train_data), \n",
    "                                 train_model.transform(test_data), \n",
    "                                 train_data, test_data)\n",
    "    \n",
    "    #Hierarchical clustering\n",
    "    HC = heiracheral_clustering(train_model.transform(train_data), \n",
    "                                train_data)\n",
    "    \n",
    "    #Random Forrest\n",
    "    RMF = random_forrest(train_model.transform(train_data), \n",
    "                         train_model.transform(test_data), \n",
    "                         train_data, test_data)\n",
    "\n",
    "    \n",
    "    #KNN 1, 3, and 5 nearest neighbors\n",
    "    KNN1 = nearest_neighbor(train_model.transform(train_data), \n",
    "                            train_model.transform(test_data), \n",
    "                            train_data, test_data, 1)\n",
    "    KNN3 = nearest_neighbor(train_model.transform(train_data), \n",
    "                            train_model.transform(test_data), \n",
    "                            train_data, test_data, 3)\n",
    "    KNN5 = nearest_neighbor(train_model.transform(train_data), \n",
    "                            train_model.transform(test_data), \n",
    "                            train_data, test_data, 5)\n",
    "    \n",
    "    f1_data = pd.DataFrame([[make_metrics_clean(KMC)[0], make_metrics_clean(HC)[0], \n",
    "                            make_metrics_clean(RMF)[0], make_metrics_clean(KNN1)[0], \n",
    "                            make_metrics_clean(KNN3)[0], make_metrics_clean(KNN5)[0],\n",
    "                            C, data_split, \"F1\"]],   \n",
    "                           columns = ['KMC', 'HC', \"RMF\", 'KNN1', \"KNN3\",\n",
    "                                      \"KNN5\", \"C\", \"data_split\", \"type\"])\n",
    "    precision = pd.DataFrame([[make_metrics_clean(KMC)[1], make_metrics_clean(HC)[1], \n",
    "                            make_metrics_clean(RMF)[1], make_metrics_clean(KNN1)[1], \n",
    "                            make_metrics_clean(KNN3)[1], make_metrics_clean(KNN5)[1],\n",
    "                            C, data_split, \"precision\"]],   \n",
    "                           columns = ['KMC', 'HC', \"RMF\", 'KNN1', \"KNN3\",\n",
    "                                      \"KNN5\", \"C\", \"data_split\", \"type\"])\n",
    "    recall = pd.DataFrame([[make_metrics_clean(KMC)[2], make_metrics_clean(HC)[2], \n",
    "                            make_metrics_clean(RMF)[2], make_metrics_clean(KNN1)[2], \n",
    "                            make_metrics_clean(KNN3)[2], make_metrics_clean(KNN5)[2],\n",
    "                            C, data_split, \"recall\"]],   \n",
    "                           columns = ['KMC', 'HC', \"RMF\", 'KNN1', \"KNN3\",\n",
    "                                      \"KNN5\", \"C\", \"data_split\", \"type\"])\n",
    "    \n",
    "    f1_data = pd.concat([f1_data, precision, recall], axis = 0)\n",
    "    # Create the figure and axes\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(18, 6))    \n",
    "    disp0 = make_confusion_matrix(KMC, \"K-Means\", axs[0], 1)\n",
    "    disp1 = make_confusion_matrix(HC, \"Heiracheral Clustering\", axs[1])\n",
    "    disp2 = make_confusion_matrix(RMF, \"Random Forrest\", axs[2])\n",
    "    disp3 = make_confusion_matrix(KNN1, \"K Nearest Neighbor N=1\", axs[3])\n",
    "    disp4 = make_confusion_matrix(KNN3, \"K Nearest Neighbor N=3\", axs[4])\n",
    "    disp5 = make_confusion_matrix(KNN5, \"K Nearest Neighbor N=5\", axs[5])\n",
    "\n",
    "    # Adjusting spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    title = \"Confusion Matricies/Confusion \" + str(C) + \" Features \" + str(data_split) + \" Train Data\" \n",
    "    plt.savefig(title +\".png\")\n",
    "    title = \"Article Characterization: \" + str(C) + \" Features \" + str(data_split) + \"% Train Data\" \n",
    "    # Display the plot\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "    return f1_data\n",
    "\n",
    "f1_data = pd.DataFrame()\n",
    "c_values = [50, 25, 12, 8, 4, 2]\n",
    "data_split_values = [90, 50, 20, 10]\n",
    "#split_data(df, percent)\n",
    "#pd.concat([f1_data, model_build_and_test(train_data, test_data, 50, 90)], axis = 0)\n",
    "#print(f1_data)\n",
    "\n",
    "for percent in data_split_values:\n",
    "    train_data, test_data = split_data(text_dataframe, percent)\n",
    "    for c in c_values:\n",
    "        f1_new = model_build_and_test(train_data, test_data, c, percent)\n",
    "        f1_data = pd.concat([f1_data, f1_new], axis = 0)\n",
    "#save data for late use when this is blocked out.\n",
    "f1_data.to_csv('f1_data.csv')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Confusion Matrixs**\n",
    "\n",
    "https://github.com/isaac1987a/BBC-Mini-Project/tree/main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load data from skipped step\n",
    "f1_data = pd.read_csv('https://raw.githubusercontent.com/isaac1987a/Week-4/main/BBC/f1_data.csv?token=GHSAT0AAAAAACEVGSIIREHWH2ZYGII3JA4KZFMJTFA')\n",
    "#print(f1_data)\n",
    "#Format Data\n",
    "f1_data = f1_data.drop('Unnamed: 0', axis = 1)\n",
    "new_data = f1_data.melt(id_vars=['data_split', 'C', 'type'])\n",
    "new_data['C'] = new_data['C'].astype('category')\n",
    "new_data['data_split'] = new_data['data_split'].astype('category')\n",
    "    \n",
    "#C/F1 Score Train 20% data\n",
    "new_data = new_data.loc[(new_data['data_split'] == 20) & (new_data['type'] == 'F1')]\n",
    "#print(new_data)\n",
    "sns.lineplot(data=new_data, x='C', y='value', hue='variable', marker ='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs. C for Different Models 20% train data')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#train_data/F1 Score C=12\n",
    "new_data = f1_data.melt(id_vars=['data_split', 'C', 'type'])\n",
    "new_data['C'] = new_data['C'].astype('category')\n",
    "new_data['data_split'] = new_data['data_split'].astype('category')\n",
    "    \n",
    "#C/F1 Score Train 20% data\n",
    "new_data = new_data.loc[(new_data['C'] == 12) & (new_data['type'] == 'F1')]\n",
    "sns.lineplot(data=new_data, x='data_split', y='value', hue='variable', marker ='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Percent Train')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs. C for Different Models')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analasys**\n",
    "The best place for getting good data seems to be around 12 factors.  This is likely becuase the algorithim has enough data to work with but minimizing the curse of dimmioniality.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
